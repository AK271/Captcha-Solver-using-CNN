{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smoking-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import PIL \n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "from numpy import asarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medieval-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory  = \"./DataSet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norwegian-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Get the first word in the filepath\n",
    "\n",
    "def parse_filepath(filepath):\n",
    "    path, filename = os.path.split(filepath)\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    label = filename.split(\"_\")\n",
    "    #print(label)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prompt-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2a5pf</td>\n",
       "      <td>./DataSet/2a5pf.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels             filepath\n",
       "count       9                    9\n",
       "unique      9                    9\n",
       "top     2a5pf  ./DataSet/2a5pf.jpg\n",
       "freq        1                    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting the Images into a dataframe so that it can be passed easily.\n",
    "# Here the images filepath is put along with that of the labels.\n",
    "import glob\n",
    "\n",
    "\n",
    "files = glob.glob(os.path.join(directory,\"*.jpg\"))\n",
    "# print(files)\n",
    "labels = list(files)\n",
    "labels = list(map(parse_filepath,files))\n",
    "# print(labels)\n",
    "df = pd.DataFrame(labels)\n",
    "df['filepath'] = files\n",
    "df.columns = ['labels','filepath']\n",
    "df.dropna()\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "running-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the size of one image file \n",
    "\n",
    "def img_size():\n",
    "    x =files[0]\n",
    "    image = Image.open(x)\n",
    "    print(image.mode)\n",
    "    return (image.size)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "developmental-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_vec_pos(char):\n",
    "    ascii_val = ord(char)\n",
    "    if ascii_val >= 48 and ascii_val<=57:\n",
    "        return ascii_val-48\n",
    "    if ascii_val >= 97 and ascii_val <=122:\n",
    "        return (ascii_val-97)+10\n",
    "    raise ValueError('Wrong character {}'.format(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brief-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_vec(word):\n",
    "    CHAR_VOCAB_SIZE = 36\n",
    "    word_len = len(word)\n",
    "    vec = np.zeros(word_len * CHAR_VOCAB_SIZE)\n",
    "\n",
    "    for i,char in enumerate(word):\n",
    "        idx = (i*CHAR_VOCAB_SIZE)+char_to_vec_pos(char)\n",
    "        vec[idx]=1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "plastic-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "def pass_Data(df,indices,training_bool,batch_size=16):\n",
    "    \n",
    "    images, labels = [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, label = r['filepath'], r['labels']\n",
    "            im = Image.open(file)\n",
    "            im = im.resize((227, 227))\n",
    "            im = np.array(im) / 255.0\n",
    "            images.append(np.array(im))\n",
    "            labels.append(np.array([words_to_vec(label)]))\n",
    "            print(im.size)\n",
    "            if len(images) >= batch_size:\n",
    "                yield np.array(images), np.array(labels)\n",
    "                images, labels = [], []\n",
    "        if not training_bool:\n",
    "            break\n",
    "    print(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "composed-participation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count: 5, valid count: 2, test count: 2\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data set into test train and validation set\n",
    "\n",
    "p = np.random.permutation(len(df)) # random images are distributed.\n",
    "train_up_to = int(len(df) * 0.8) # the train and the test set is divided into 80:20 \n",
    "train_idx = p[:train_up_to]\n",
    "test_idx = p[train_up_to:]\n",
    "\n",
    "# split train_idx further into training and validation set\n",
    "train_up_to = int(train_up_to * 0.8) # the train set is further divided into the validation and the training data set\n",
    "train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "print('train count: %s, valid count: %s, test count: %s' % (\n",
    "    len(train_idx), len(valid_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "advanced-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generating the test and the validation data \n",
    "\n",
    "batch_size = 2# insert Number\n",
    "valid_batch_size = 1 #inset Number \n",
    "\n",
    "# def pass_Data(df,indices,training_bool,batch_size=16)\n",
    "train_gen = pass_Data(df,train_idx,True,batch_size = batch_size)\n",
    "validation_gen = pass_Data(df,valid_idx,True,batch_size = valid_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "amber-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "# To calculate the validation and the training steps\n",
    "\n",
    "validation_steps = (len(valid_idx)//valid_batch_size)\n",
    "train_steps = (len(train_idx)//batch_size)\n",
    "print(validation_steps,train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "enormous-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Alex_net Model making\n",
    "def Alex_net():\n",
    "#     THe input shape is always 257*257*3 or 256*256*3 and the images should be reshaped into it, if it is not that currently\n",
    "    image_shape = (227,227,3)\n",
    "    np.random.seed(1000)\n",
    "    model = Sequential()\n",
    "#     First Layer which is the convolution Layer\n",
    "    model.add(Conv2D(filters = 96,input_shape = image_shape,kernel_size=(11,11),strides=(4,4),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "#     Next is the Pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = 'valid'))\n",
    "\n",
    "#     The first convolution and max pooling layer is done .\n",
    "\n",
    "#     Second Layer \n",
    "    model.add(Conv2D(filters = 256,kernel_size=(5,5),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "#     Next is the Pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = 'valid'))\n",
    "    \n",
    "#     Second Layer Done \n",
    "\n",
    "#     Third Layer is only the convolution layer. There is no maxPooling layer at all\n",
    "\n",
    "    model.add(Conv2D(filters = 384,kernel_size=(3,3),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Fourth layer- only convolution layer\n",
    "    \n",
    "    model.add(Conv2D(filters = 384,kernel_size=(3,3),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "# Fifth layer- one convolution and one pooling layer\n",
    "    model.add(Conv2D(filters = 256,kernel_size=(3,3),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = 'valid'))\n",
    "\n",
    "        \n",
    "    model.add(Flatten())\n",
    "# Sixth fully connected layer\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "#Seventh fully connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "#Final softmax layer\n",
    "    model.add(Dense(36*5))\n",
    "#     model.resize()\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"])\n",
    "    history = model.fit(train_gen,steps_per_epoch= train_steps,epochs = 2,validation_data = validation_gen, validation_steps = validation_steps)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "alone-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 5, 5, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 180)               737460    \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 180)               0         \n",
      "=================================================================\n",
      "Total params: 25,464,372\n",
      "Trainable params: 25,464,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "154587\n",
      "154587\n",
      "Epoch 1/2\n",
      "154587\n",
      "154587\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Can not squeeze dim[2], expected a dimension of 1, got 180\n\t [[node categorical_crossentropy/remove_squeezable_dimensions/Squeeze (defined at <ipython-input-73-46e8f784ad11>:59) ]] [Op:__inference_train_function_11324]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-cc240619ba25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAlex_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-46e8f784ad11>\u001b[0m in \u001b[0;36mAlex_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Can not squeeze dim[2], expected a dimension of 1, got 180\n\t [[node categorical_crossentropy/remove_squeezable_dimensions/Squeeze (defined at <ipython-input-73-46e8f784ad11>:59) ]] [Op:__inference_train_function_11324]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "Alex_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-reset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-exception",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
