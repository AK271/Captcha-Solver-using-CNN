{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "smoking-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import PIL \n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "from numpy import asarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "medieval-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory  = \"./DataSet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "norwegian-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Get the first word in the filepath\n",
    "\n",
    "def parse_filepath(filepath):\n",
    "    path, filename = os.path.split(filepath)\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    label = filename.split(\"_\")\n",
    "    #print(label)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "prompt-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2a5cn</td>\n",
       "      <td>./DataSet/2a6y6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels             filepath\n",
       "count       9                    9\n",
       "unique      9                    9\n",
       "top     2a5cn  ./DataSet/2a6y6.jpg\n",
       "freq        1                    1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting the Images into a dataframe so that it can be passed easily.\n",
    "# Here the images filepath is put along with that of the labels.\n",
    "import glob\n",
    "\n",
    "\n",
    "files = glob.glob(os.path.join(directory,\"*.jpg\"))\n",
    "# print(files)\n",
    "labels = list(files)\n",
    "labels = list(map(parse_filepath,files))\n",
    "# print(labels)\n",
    "df = pd.DataFrame(labels)\n",
    "df['filepath'] = files\n",
    "df.columns = ['labels','filepath']\n",
    "df.dropna()\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "running-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the size of one image file \n",
    "\n",
    "def img_size():\n",
    "    x =files[0]\n",
    "    image = Image.open(x)\n",
    "    print(image.mode)\n",
    "    return (image.size)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "plastic-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "def pass_Data(df,indices,training_bool,batch_size=16):\n",
    "  images, labels = [], []\n",
    "  while True:\n",
    "    for i in indices:\n",
    "      r = df.iloc[i]\n",
    "      file, label = r['filepath'], r['labels']\n",
    "      im = Image.open(file)\n",
    "      im = np.array(im) / 255.0\n",
    "      images.append(np.array(im))\n",
    "      labels.append(np.array([np.array(to_categorical(int(i), 10)) for i in label]))\n",
    "      if len(images) >= batch_size:\n",
    "          yield np.array(images), np.array(labels)\n",
    "          images, labels = [], []\n",
    "    if not training_bool:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "composed-participation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count: 5, valid count: 2, test count: 2\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data set into test train and validation set\n",
    "\n",
    "p = np.random.permutation(len(df)) # random images are distributed.\n",
    "train_up_to = int(len(df) * 0.8) # the train and the test set is divided into 80:20 \n",
    "train_idx = p[:train_up_to]\n",
    "test_idx = p[train_up_to:]\n",
    "\n",
    "# split train_idx further into training and validation set\n",
    "train_up_to = int(train_up_to * 0.8) # the train set is further divided into the validation and the training data set\n",
    "train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "print('train count: %s, valid count: %s, test count: %s' % (\n",
    "    len(train_idx), len(valid_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "advanced-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generating the test and the validation data \n",
    "\n",
    "batch_size = 2# insert Number\n",
    "valid_batch_size = 1 #inset Number \n",
    "\n",
    "# def pass_Data(df,indices,training_bool,batch_size=16)\n",
    "train_gen = pass_Data(df,train_idx,True,batch_size = batch_size)\n",
    "validation_gen = pass_Data(df,valid_idx,True,batch_size = valid_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "amber-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "# To calculate the validation and the training steps\n",
    "\n",
    "validation_steps = (len(valid_idx)//valid_batch_size)\n",
    "train_steps = (len(train_idx)//batch_size)\n",
    "print(validation_steps,train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "enormous-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Alex_net Model making\n",
    "def Alex_net():\n",
    "#     THe input shape is always 257*257*3 or 256*256*3 and the images should be reshaped into it, if it is not that currently\n",
    "    image_shape = (227,227,3)\n",
    "    np.random.seed(1000)\n",
    "    model = Sequential()\n",
    "#     First Layer which is the convolution Layer\n",
    "    model.add(Conv2D(filters = 96,input_shape = image_shape,kernel_size=(11,11),strides=(4,4),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "#     Next is the Pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = 'valid'))\n",
    "\n",
    "#     The first convolution and max pooling layer is done .\n",
    "\n",
    "#     Second Layer \n",
    "    model.add(Conv2D(filters = 256,kernel_size=(5,5),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "#     Next is the Pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = 'valid'))\n",
    "    \n",
    "#     Second Layer Done \n",
    "\n",
    "#     Third Layer is only the convolution layer. There is no maxPooling layer at all\n",
    "\n",
    "    model.add(Conv2D(filters = 384,kernel_size=(3,3),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Fourth layer- only convolution layer\n",
    "    \n",
    "    model.add(Conv2D(filters = 384,kernel_size=(3,3),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "# Fifth layer- one convolution and one pooling layer\n",
    "    model.add(Conv2D(filters = 256,kernel_size=(3,3),strides=(1,1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = 'valid'))\n",
    "\n",
    "        \n",
    "    model.add(Flatten())\n",
    "# Sixth fully connected layer\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "#Seventh fully connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "#Final softmax layer\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"])\n",
    "    history = model.fit(train_gen,steps_per_epoch= train_steps,epochs = 2,validation_data = valid_gen, validation_steps = validation_steps)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aging-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 5, 5, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 28,823,912\n",
      "Trainable params: 28,823,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-cc16e848c99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlex_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-99e4d59ab236>\u001b[0m in \u001b[0;36mAlex_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = Alex_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-hollywood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
